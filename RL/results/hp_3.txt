HarryPotterWorld
Feature data:
{'x1': {'mean': 0, 'std': 1}, 'x2': {'mean': 0, 'std': 1}}
Actions: 
{'x2': {'step_range': [0, 0.05], 'max_change': [0, 0.4]}}
Terminal Reward: 50



{'actor_lr': 0.001, 'critic_lr': 0.01, 'gamma': 0.95, 'tau': 0.01, 'buffer_size': 5000, 'minibatch_size': 25, 'max_episodes': 150, 'max_episode_len': 50, 'random_seed': 123, 'max_final_steps': 50, 'summary_dir': './results/tf_ddpg', 'env': <harrypotterworld.HarryPotterWorld object at 0x000001F1C66855F8>} 


Initial State:  x2:0.327 | 
Reward:48.523 | Episode:10 | Qmax:2.3650 | Episode Length:10 |  True | x2:0.630 | 
Reward:48.406 | Episode:20 | Qmax:7.0537 | Episode Length:8 |  True | x2:0.645 | 
Reward:48.471 | Episode:30 | Qmax:10.2927 | Episode Length:7 |  True | x2:0.637 | 
Reward:48.596 | Episode:40 | Qmax:14.7151 | Episode Length:7 |  True | x2:0.620 | 
Reward:48.501 | Episode:50 | Qmax:19.3462 | Episode Length:9 |  True | x2:0.633 | 
Reward:48.404 | Episode:60 | Qmax:24.3809 | Episode Length:8 |  True | x2:0.645 | 
Reward:48.399 | Episode:70 | Qmax:27.7793 | Episode Length:7 |  True | x2:0.646 | 
Reward:48.636 | Episode:80 | Qmax:33.3005 | Episode Length:6 |  True | x2:0.614 | 
Reward:48.519 | Episode:90 | Qmax:34.3542 | Episode Length:6 |  True | x2:0.630 | 
Reward:48.613 | Episode:100 | Qmax:36.8835 | Episode Length:5 |  True | x2:0.617 | 
Reward:48.421 | Episode:110 | Qmax:37.5554 | Episode Length:8 |  True | x2:0.643 | 
Reward:48.389 | Episode:120 | Qmax:37.9839 | Episode Length:8 |  True | x2:0.647 | 
Reward:48.500 | Episode:130 | Qmax:38.7690 | Episode Length:10 |  True | x2:0.633 | 
Reward:48.462 | Episode:140 | Qmax:38.6460 | Episode Length:10 |  True | x2:0.638 | 
Reward:48.601 | Episode:150 | Qmax:38.5189 | Episode Length:8 |  True | x2:0.619 | 
Done training


Initial State: 
x2:0.327 | 
State: [0.] Action 1 : [0.99881715] Next State: [0.04997043]
[0.99881715] : x2 : 0.04997042864561081    
State: [0.04997043] Action 2 : [0.99896663] Next State: [0.09994459]
[0.99896663] : x2 : 0.049974165856838226    
State: [0.09994459] Action 3 : [0.9990972] Next State: [0.14992203]
[0.9990972] : x2 : 0.0499774307012558    
State: [0.14992203] Action 4 : [0.9992115] Next State: [0.19990231]
[0.9992115] : x2 : 0.04998028725385666    
State: [0.19990231] Action 5 : [0.99931115] Next State: [0.24988509]
[0.99931115] : x2 : 0.04998277872800827    
State: [0.24988509] Action 6 : [0.9993984] Next State: [0.29987005]
[0.9993984] : x2 : 0.049984960258007055    
Final State: 
x2:0.627 | 
Total Reward: 48.54135556758354
