{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# For plotting data\n",
    "def plot_model(X_train, y_train, clf, X_trust=None, y_trust=None, title=None, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\ttrain_cluster_labels=None, trust_cluster_labels=None):\n",
    "\t\n",
    "\tpca = PCA(n_components=2)\n",
    "\tX_train_2d = pca.fit_transform(X_train)\n",
    "\tX_trust_2d = pca.transform(X_trust)\n",
    "\n",
    "\t# X = np.zeros((10000,2))\n",
    "\t# a = np.linspace(0,1,100)\n",
    "\t# b = np.linspace(0,1,100)\n",
    "\t# e, d = np.meshgrid(a, b)\n",
    "\t# X[:,0] = np.reshape(e,(10000,))\n",
    "\t# X[:,1] = np.reshape(d,(10000,))\n",
    "\n",
    "\t# Z = clf.predict(X)\n",
    "\t# probs = clf.predict_proba(K)[:, 1].reshape(e.shape)\n",
    "\n",
    "\tplt.figure()\n",
    "\n",
    "\t# Put the result into a color plot\n",
    "\t# Z = Z.reshape(e.shape)\n",
    "\t# plt.contour(e, d, probs, levels=[0.5])\n",
    "\n",
    "\t# Plot clusters\n",
    "\tif train_cluster_labels is not None:\n",
    "\t\tif trust_cluster_labels is not None:\n",
    "\t\t\tcluster_labels = np.concatenate([train_cluster_labels,trust_cluster_labels])\n",
    "\t\t\tX = np.vstack([X_train_2d, X_trust_2d])\n",
    "\t\t\tplt.scatter(X[:, 0], X[:, 1], c=cluster_labels, marker='o', s=80)\n",
    "\t\telse:\n",
    "\t\t\tplt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=train_cluster_labels, marker='o', s=80)\n",
    "\n",
    "\t# Plot the training points\n",
    "\tplt.scatter(X_train_2d[:, 0], X_train_2d[:, 1], c=y_train, cmap=plt.cm.Paired, marker='.')\n",
    "\t\n",
    "\t# Plot the trusted points\n",
    "\tif X_trust_2d is not None:\n",
    "\t\tplt.scatter(X_trust_2d[:, 0], X_trust_2d[:, 1], c=y_trust, cmap=plt.cm.Paired, marker='X')\n",
    "\n",
    "\tif title is not None:\n",
    "\t\tplt.title(str(title))\n",
    "\n",
    "\tplt.xlabel('x1')\n",
    "\tplt.ylabel('x2')\n",
    "\tplt.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Dendrogram...\n",
    "https://github.com/scikit-learn/scikit-learn/blob/70cf4a676caa2d2dad2e3f6e4478d64bcb0506f7/examples/cluster/plot_hierarchical_clustering_dendrogram.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    \n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    \n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GermanLoan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset...\n",
      "(1000, 25)\n",
      "(1000, 24) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# read dataset\n",
    "col_names = ['Checking Status', 'Duration','Credit History', 'Credit Amt','Purpose', \n",
    "              'Saving acc', 'Present emp since', 'Installment Rate',\n",
    "             'Personal Status', 'Age', 'Other debtors', 'Present Residence since', 'Property',\n",
    "              'Other installment plans', 'Housing', 'Existing credits',\n",
    "             'Job', 'Num People', 'Telephone', 'Foreign Worker','a','b','c','d','Approval Status']\n",
    "\n",
    "numerical = ['Duration','Credit Amt','Age']\n",
    "\n",
    "print(\"Reading dataset...\")\n",
    "all_data = pd.read_csv(\"germanloan.csv\", names=col_names)\n",
    "print(all_data.shape)\n",
    "\n",
    "n = all_data.shape[0]\n",
    "X = all_data[all_data.columns.difference(['Approval Status'])]\n",
    "y = all_data['Approval Status']\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Checking Status</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Credit History</th>\n",
       "      <th>Credit Amt</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Saving acc</th>\n",
       "      <th>Present emp since</th>\n",
       "      <th>Installment Rate</th>\n",
       "      <th>Personal Status</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Existing credits</th>\n",
       "      <th>Job</th>\n",
       "      <th>Num People</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>Foreign Worker</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>Approval Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Checking Status  Duration  Credit History  Credit Amt  Purpose  \\\n",
       "0                 1         6               4          12        5   \n",
       "1                 2        48               2          60        1   \n",
       "2                 4        12               4          21        1   \n",
       "3                 1        42               2          79        1   \n",
       "4                 1        24               3          49        1   \n",
       "5                 4        36               2          91        5   \n",
       "6                 4        24               2          28        3   \n",
       "7                 2        36               2          69        1   \n",
       "8                 4        12               2          31        4   \n",
       "9                 2        30               4          52        1   \n",
       "10                2        12               2          13        1   \n",
       "11                1        48               2          43        1   \n",
       "12                2        12               2          16        1   \n",
       "13                1        24               4          12        1   \n",
       "14                1        15               2          14        1   \n",
       "15                1        24               2          13        2   \n",
       "16                4        24               4          24        5   \n",
       "17                1        30               0          81        5   \n",
       "18                2        24               2         126        1   \n",
       "19                4        24               2          34        3   \n",
       "20                4         9               4          21        1   \n",
       "21                1         6               2          26        3   \n",
       "22                1        10               4          22        1   \n",
       "23                2        12               4          18        2   \n",
       "24                4        10               4          21        5   \n",
       "25                1         6               2          14        1   \n",
       "26                4         6               0           4        1   \n",
       "27                3        12               1           4        4   \n",
       "28                2         7               2          24        1   \n",
       "29                1        60               3          68        1   \n",
       "\n",
       "    Saving acc  Present emp since  Installment Rate  Personal Status  Age  \\\n",
       "0            5                  3                 4                1   67   \n",
       "1            3                  2                 2                1   22   \n",
       "2            4                  3                 3                1   49   \n",
       "3            4                  3                 4                2   45   \n",
       "4            3                  3                 4                4   53   \n",
       "5            3                  3                 4                4   35   \n",
       "6            5                  3                 4                2   53   \n",
       "7            3                  3                 2                3   35   \n",
       "8            4                  1                 4                1   61   \n",
       "9            1                  4                 2                3   28   \n",
       "10           2                  2                 1                3   25   \n",
       "11           2                  2                 4                2   24   \n",
       "12           3                  2                 1                3   22   \n",
       "13           5                  3                 4                3   60   \n",
       "14           3                  2                 4                3   28   \n",
       "15           3                  2                 2                3   32   \n",
       "16           5                  3                 4                2   53   \n",
       "17           2                  3                 3                3   25   \n",
       "18           5                  2                 2                4   44   \n",
       "19           5                  3                 2                3   31   \n",
       "20           3                  3                 4                3   48   \n",
       "21           3                  3                 3                1   44   \n",
       "22           2                  3                 3                1   48   \n",
       "23           2                  3                 4                2   44   \n",
       "24           3                  4                 1                3   26   \n",
       "25           3                  3                 2                1   36   \n",
       "26           5                  4                 4                3   39   \n",
       "27           3                  2                 3                1   42   \n",
       "28           3                  3                 2                1   34   \n",
       "29           5                  3                 4                4   63   \n",
       "\n",
       "         ...         Existing credits  Job  Num People  Telephone  \\\n",
       "0        ...                        0    0           1          0   \n",
       "1        ...                        0    0           1          0   \n",
       "2        ...                        0    0           1          0   \n",
       "3        ...                        0    0           0          0   \n",
       "4        ...                        1    0           1          0   \n",
       "5        ...                        0    0           1          0   \n",
       "6        ...                        0    0           1          0   \n",
       "7        ...                        0    1           1          0   \n",
       "8        ...                        0    0           1          0   \n",
       "9        ...                        1    0           1          0   \n",
       "10       ...                        1    0           1          0   \n",
       "11       ...                        0    0           1          0   \n",
       "12       ...                        0    0           1          0   \n",
       "13       ...                        1    0           1          0   \n",
       "14       ...                        1    0           1          0   \n",
       "15       ...                        0    0           1          0   \n",
       "16       ...                        0    0           1          0   \n",
       "17       ...                        0    0           1          0   \n",
       "18       ...                        0    1           1          0   \n",
       "19       ...                        0    0           1          0   \n",
       "20       ...                        1    0           1          0   \n",
       "21       ...                        0    0           1          0   \n",
       "22       ...                        1    0           1          0   \n",
       "23       ...                        0    1           1          0   \n",
       "24       ...                        0    0           1          0   \n",
       "25       ...                        0    0           1          0   \n",
       "26       ...                        0    0           1          0   \n",
       "27       ...                        0    0           1          0   \n",
       "28       ...                        0    0           0          0   \n",
       "29       ...                        0    0           1          0   \n",
       "\n",
       "    Foreign Worker  a  b  c  d  Approval Status  \n",
       "0                0  1  0  0  1                1  \n",
       "1                0  1  0  0  1                2  \n",
       "2                0  1  0  1  0                1  \n",
       "3                0  0  0  0  1                1  \n",
       "4                0  0  0  0  1                2  \n",
       "5                0  0  0  1  0                1  \n",
       "6                0  1  0  0  1                1  \n",
       "7                1  0  0  0  0                1  \n",
       "8                0  1  0  1  0                1  \n",
       "9                0  1  0  0  0                2  \n",
       "10               1  0  0  0  1                2  \n",
       "11               1  0  0  0  1                2  \n",
       "12               0  1  0  0  1                1  \n",
       "13               0  1  0  1  0                2  \n",
       "14               1  0  0  0  1                1  \n",
       "15               0  1  0  1  0                2  \n",
       "16               0  1  0  0  1                1  \n",
       "17               0  1  0  0  1                1  \n",
       "18               0  0  0  0  0                2  \n",
       "19               0  1  0  0  1                1  \n",
       "20               0  1  0  0  1                1  \n",
       "21               1  0  0  0  1                1  \n",
       "22               1  0  0  1  0                1  \n",
       "23               0  1  0  0  1                1  \n",
       "24               0  1  0  0  1                1  \n",
       "25               0  1  0  1  0                1  \n",
       "26               0  1  0  1  0                1  \n",
       "27               1  0  0  0  1                1  \n",
       "28               0  1  0  0  1                1  \n",
       "29               0  1  0  0  1                2  \n",
       "\n",
       "[30 rows x 25 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set 1=good, -1=bad in y\n",
    "y[y==2] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X.loc[:,['Duration','Credit Amt']] = scaler.fit_transform(X.loc[:,['Duration','Credit Amt']].astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 24) (810, 24)\n"
     ]
    }
   ],
   "source": [
    "# partition dataset on the basis of age, threshold = 25\n",
    "X_y = X[X['Age']<=25]\n",
    "X_o = X[X['Age']>25]\n",
    "y_y = y[X['Age']<=25]\n",
    "y_o = y[X['Age']>25]\n",
    "print(X_y.shape, X_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Checking Status</th>\n",
       "      <th>Credit Amt</th>\n",
       "      <th>Credit History</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Existing credits</th>\n",
       "      <th>Foreign Worker</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Installment Rate</th>\n",
       "      <th>Job</th>\n",
       "      <th>...</th>\n",
       "      <th>Present Residence since</th>\n",
       "      <th>Present emp since</th>\n",
       "      <th>Property</th>\n",
       "      <th>Purpose</th>\n",
       "      <th>Saving acc</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Checking Status  Credit Amt  Credit History  Duration  \\\n",
       "1    22                2          60               2        48   \n",
       "10   25                2          13               2        12   \n",
       "\n",
       "    Existing credits  Foreign Worker  Housing  Installment Rate  Job ...  \\\n",
       "1                  0               0        1                 2    0 ...   \n",
       "10                 1               1        1                 1    0 ...   \n",
       "\n",
       "    Present Residence since  Present emp since  Property  Purpose  Saving acc  \\\n",
       "1                         1                  2         1        1           3   \n",
       "10                        1                  2         1        1           2   \n",
       "\n",
       "    Telephone  a  b  c  d  \n",
       "1           0  1  0  0  1  \n",
       "10          0  0  0  0  1  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 23) (810, 23)\n"
     ]
    }
   ],
   "source": [
    "# Remove age as a feature\n",
    "del X_y['Age']\n",
    "del X_o['Age']\n",
    "\n",
    "print(X_y.shape, X_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting to numpy arrays\n",
    "X_young = X_y.values\n",
    "X_old = X_o.values\n",
    "y_young = y_y.values\n",
    "y_old = y_o.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 23) (810, 23)\n"
     ]
    }
   ],
   "source": [
    "print(X_young.shape, X_old.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random arrays for partitioning into A,B,C datasets\n",
    "np.random.seed(123)\n",
    "young = np.random.permutation(np.arange(X_young.shape[0]))\n",
    "old = np.random.permutation(np.arange(X_old.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets A, B and C...\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "print(\"Creating datasets A, B and C...\")\n",
    "# Create dataset A (trusted dataset)\n",
    "X_A = np.concatenate((X_young[young[:20],:],X_old[old[:20],:]))\n",
    "y_A = np.concatenate((y_young[young[:20]],y_old[old[:20]]))\n",
    "# print(X_A.shape,y_A.shape)\n",
    "\n",
    "# Create dataset B (buggy dataset)\n",
    "X_B = np.concatenate((X_young[young[20:190],:],X_old[old[20:190],:]))\n",
    "y_B = np.concatenate((y_young[young[20:190]],y_old[old[20:190]]))\n",
    "# print(X_B.shape,y_B.shape)\n",
    "\n",
    "# Create dataset C (ground truth)\n",
    "X_C = X_old[old[190:],:]\n",
    "y_C = y_old[old[190:]]\n",
    "# print(X_C.shape,y_C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model on dataset C...\n",
      "Creating trusted labels for dataset A...\n",
      "Number of label changes made in Dataset A to make it trusted: 11\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "print(\"Training Model on dataset C...\")\n",
    "\n",
    "# the learner is hard coded to be logistic regression\n",
    "lam = 5e-3\t# L2 regularization weight of learner\n",
    "\n",
    "# Training model f* on dataset C\n",
    "clf = LogisticRegression(solver='lbfgs', C=lam)\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "\n",
    "\n",
    "clf.fit(X_C, y_C)\n",
    "y_C_pred = clf.predict(X_C)\n",
    "\n",
    "print(\"Creating trusted labels for dataset A...\")\n",
    "y_A_pred = clf.predict(X_A)\n",
    "\n",
    "print(\"Number of label changes made in Dataset A to make it trusted: %d\"%np.count_nonzero(y_A-y_A_pred)),\"\\n\"\n",
    "y_A = y_A_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Gower Function\n",
    "https://sourceforge.net/projects/gower-distance-4python/files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance \n",
    "from sklearn.utils import validation\n",
    "from sklearn.metrics import pairwise\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_pairwise_arrays(X, Y, precomputed=False, dtype=None):\n",
    "    X, Y, dtype_float = pairwise._return_float_dtype(X, Y)\n",
    "\n",
    "    warn_on_dtype = dtype is not None\n",
    "    estimator = 'check_pairwise_arrays'\n",
    "    if dtype is None:\n",
    "        dtype = dtype_float\n",
    "\n",
    "    if Y is X or Y is None:\n",
    "        X = Y = validation.check_array(X, accept_sparse='csr', dtype=dtype,\n",
    "                            warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
    "    else:\n",
    "        X = validation.check_array(X, accept_sparse='csr', dtype=dtype,\n",
    "                        warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
    "        Y = validation.check_array(Y, accept_sparse='csr', dtype=dtype,\n",
    "                        warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
    "\n",
    "    if precomputed:\n",
    "        if X.shape[1] != Y.shape[0]:\n",
    "            raise ValueError(\"Precomputed metric requires shape \"\n",
    "                             \"(n_queries, n_indexed). Got (%d, %d) \"\n",
    "                             \"for %d indexed.\" %\n",
    "                             (X.shape[0], X.shape[1], Y.shape[0]))\n",
    "    elif X.shape[1] != Y.shape[1]:\n",
    "        raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n",
    "                         \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n",
    "                             X.shape[1], Y.shape[1]))\n",
    "\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Vectorized Version\n",
    "def gower_distances(X, Y=None, feature_weight=None, categorical_features=None):\n",
    "    \"\"\"Computes the gower distances between X and Y\n",
    "\n",
    "    Gower is a similarity measure for categorical, boolean and numerical mixed\n",
    "    data.\n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, or pandas.DataFrame, shape (n_samples, n_features)\n",
    "\n",
    "    Y : array-like, or pandas.DataFrame, shape (n_samples, n_features)\n",
    "\n",
    "    feature_weight :  array-like, shape (n_features)\n",
    "        According the Gower formula, feature_weight is an attribute weight.\n",
    "\n",
    "    categorical_features: array-like, shape (n_features)\n",
    "        Indicates with True/False whether a column is a categorical attribute.\n",
    "        This is useful when categorical atributes are represented as integer\n",
    "        values. Categorical ordinal attributes are treated as numeric, and must\n",
    "        be marked as false.\n",
    "        \n",
    "        Alternatively, the categorical_features array can be represented only\n",
    "        with the numerical indexes of the categorical attribtes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    similarities : ndarray, shape (n_samples, n_samples)\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "    The non-numeric features, and numeric feature ranges are determined from X and not Y.\n",
    "    No support for sparse matrices.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if issparse(X) or issparse(Y):\n",
    "        raise TypeError(\"Sparse matrices are not supported for gower distance\")\n",
    "        \n",
    "    y_none = Y is None\n",
    "    \n",
    "    \n",
    "    # It is necessary to convert to ndarray in advance to define the dtype\n",
    "    if not isinstance(X, np.ndarray):\n",
    "        X = np.asarray(X)\n",
    "\n",
    "    array_type = np.object\n",
    "    # this is necessary as strangelly the validator is rejecting numeric\n",
    "    # arrays with NaN\n",
    "    if  np.issubdtype(X.dtype, np.number) and (np.isfinite(X.sum()) or np.isfinite(X).all()):\n",
    "        array_type = type(np.zeros(1,X.dtype).flat[0])\n",
    "    \n",
    "    X, Y = check_pairwise_arrays(X, Y, precomputed=False, dtype=array_type)\n",
    "    \n",
    "    n_rows, n_cols = X.shape\n",
    "    \n",
    "    if categorical_features is None:\n",
    "        categorical_features = np.zeros(n_cols, dtype=bool)\n",
    "        for col in range(n_cols):\n",
    "            # In numerical columns, None is converted to NaN,\n",
    "            # and the type of NaN is recognized as a number subtype\n",
    "            if not np.issubdtype(type(X[0, col]), np.number):\n",
    "                categorical_features[col]=True\n",
    "    else:          \n",
    "        categorical_features = np.array(categorical_features)\n",
    "    \n",
    "    \n",
    "    #if categorical_features.dtype == np.int32:\n",
    "    if np.issubdtype(categorical_features.dtype, np.int):\n",
    "        new_categorical_features = np.zeros(n_cols, dtype=bool)\n",
    "        new_categorical_features[categorical_features] = True\n",
    "        categorical_features = new_categorical_features\n",
    "    \n",
    "#     print(categorical_features)\n",
    "  \n",
    "    # Categorical columns\n",
    "    X_cat =  X[:,categorical_features]\n",
    "    \n",
    "    # Numerical columns\n",
    "    X_num = X[:,np.logical_not(categorical_features)]\n",
    "    ranges_of_numeric = None\n",
    "    max_of_numeric = None\n",
    "    \n",
    "        \n",
    "    # Calculates the normalized ranges and max values of numeric values\n",
    "    _ ,num_cols=X_num.shape\n",
    "    ranges_of_numeric = np.zeros(num_cols)\n",
    "    max_of_numeric = np.zeros(num_cols)\n",
    "    for col in range(num_cols):\n",
    "        col_array = X_num[:, col].astype(np.float32) \n",
    "        max = np.nanmax(col_array)\n",
    "        min = np.nanmin(col_array)\n",
    "     \n",
    "        if np.isnan(max):\n",
    "            max = 0.0\n",
    "        if np.isnan(min):\n",
    "            min = 0.0\n",
    "        max_of_numeric[col] = max\n",
    "        ranges_of_numeric[col] = (1 - min / max) if (max != 0) else 0.0\n",
    "\n",
    "\n",
    "    # This is to normalize the numeric values between 0 and 1.\n",
    "    X_num = X_num.astype(float)\n",
    "    max_of_numeric = max_of_numeric.astype(float)\n",
    "    X_num = np.divide(X_num ,max_of_numeric,out=np.zeros_like(X_num), where=max_of_numeric!=0)\n",
    "\n",
    "    \n",
    "    if feature_weight is None:\n",
    "        feature_weight = np.ones(n_cols)\n",
    "        \n",
    "    feature_weight_cat=feature_weight[categorical_features]\n",
    "    feature_weight_num=feature_weight[np.logical_not(categorical_features)]\n",
    "    \n",
    "    \n",
    "    y_n_rows, _ = Y.shape\n",
    "    \n",
    "    dm = np.zeros((n_rows, y_n_rows), dtype=np.float32)\n",
    "        \n",
    "    feature_weight_sum = feature_weight.sum()\n",
    "\n",
    "    Y_cat=None\n",
    "    Y_num=None\n",
    "    \n",
    "    if not y_none:\n",
    "        Y_cat = Y[:,categorical_features]\n",
    "        Y_num = Y[:,np.logical_not(categorical_features)]\n",
    "        # This is to normalize the numeric values between 0 and 1.\n",
    "        Y_num = np.divide(Y_num ,max_of_numeric,out=np.zeros_like(Y_num), where=max_of_numeric!=0)\n",
    "    else:\n",
    "        Y_cat=X_cat\n",
    "        Y_num = X_num\n",
    "        \n",
    "    for i in range(n_rows):\n",
    "        j_start= i\n",
    "        \n",
    "        # for non square results\n",
    "        if n_rows != y_n_rows:\n",
    "            j_start = 0\n",
    "\n",
    "      \n",
    "        Y_cat[j_start:n_rows,:]\n",
    "        Y_num[j_start:n_rows,:]\n",
    "        result= _gower_distance_row(X_cat[i,:], X_num[i,:],Y_cat[j_start:n_rows,:],\n",
    "                                    Y_num[j_start:n_rows,:],feature_weight_cat,feature_weight_num,\n",
    "                                    feature_weight_sum,categorical_features,ranges_of_numeric,\n",
    "                                    max_of_numeric) \n",
    "        dm[i,j_start:]=result\n",
    "        dm[i:,j_start]=result\n",
    "        _gower_distance_row\n",
    "\n",
    "    return dm\n",
    "\n",
    "\n",
    "def _gower_distance_row(xi_cat,xi_num,xj_cat,xj_num,feature_weight_cat,feature_weight_num,\n",
    "                        feature_weight_sum,categorical_features,ranges_of_numeric,max_of_numeric ):\n",
    "    # categorical columns\n",
    "    sij_cat = np.where(xi_cat == xj_cat,np.zeros_like(xi_cat),np.ones_like(xi_cat))\n",
    "    sum_cat = np.multiply(feature_weight_cat,sij_cat).sum(axis=1) \n",
    "\n",
    "    # numerical columns\n",
    "    abs_delta=np.absolute( xi_num-xj_num)\n",
    "    sij_num=np.divide(abs_delta, ranges_of_numeric, out=np.zeros_like(abs_delta), where=ranges_of_numeric!=0)\n",
    "\n",
    "    sum_num = np.multiply(feature_weight_num,sij_num).sum(axis=1)\n",
    "    sums= np.add(sum_cat,sum_num)\n",
    "    sum_sij = np.divide(sums,feature_weight_sum)\n",
    "    return sum_sij\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y_train,y_train_mod, y_mod_pred):\n",
    "\tprint(\"Number of label changes made in dataset: %d\" % np.count_nonzero(y_train - y_train_mod))\n",
    "\tprint(\"Model Accuracy w.r.t. Original dataset: \", \n",
    "          np.count_nonzero((y_train - y_mod_pred)==0)*100.0/y_train.shape[0])\n",
    "\tprint(\"Model Accuracy w.r.t. Modified dataset: \", \n",
    "          np.count_nonzero((y_train_mod - y_mod_pred)==0)*100.0/y_train.shape[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_trusted_items(X_train,y_train,X_trust,y_trust, clf, combo=None, \n",
    "\t\t\t\t\t\ttrain_cluster_labels=None, trust_cluster_labels=None, plot=False):\n",
    "\n",
    "\tclf.fit(X_train, y_train)\n",
    "\ty_train_pred = clf.predict(X_train)\n",
    "\n",
    "\ty_trust_pred = clf.predict(X_trust)\n",
    "\n",
    "\t# print(\"Plotting...\")\n",
    "\n",
    "\tif np.array_equal(y_trust, y_trust_pred):\n",
    "\t\tprint (\"All trusted items predicted correctly by model, combo:\",combo)\n",
    "\t\tif plot:\n",
    "\t\t\tplotting.plot_model(X_train, y_train, X_trust, y_trust, str(combo)+\" Good\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\ttrain_cluster_labels, trust_cluster_labels)\n",
    "\t\tcheck = True\n",
    "\telse:\n",
    "\t\tprint (\"%d trusted items were incorrectly predicted. Continuing experiment...\"%\n",
    "               np.count_nonzero(y_trust-y_trust_pred))\n",
    "\t\tif plot:\n",
    "\t\t\tplot_model(X_train, y_train, clf, X_trust, y_trust, str(combo)+\" Bad\", \n",
    "\t\t \t\t\t\t\t\t\t\t\t\t\ttrain_cluster_labels, trust_cluster_labels)\n",
    "\t\tcheck = False\n",
    "\treturn clf, y_train_pred, y_trust_pred, check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_labels(K, y_train, train_cluster_labels, combo, max_changes=np.inf):\n",
    "\t\n",
    "\ty_train_mod = np.copy(y_train)\n",
    "\tfor i in range(K):\n",
    "\t\ty_train_mod[train_cluster_labels==i] = combo[i]\n",
    "\t\n",
    "\tnum_changes = np.count_nonzero(y_train - y_train_mod)\n",
    "\tif num_changes>max_changes:\n",
    "\t\t# print(combo,\"Too many changes to dataset:\",num_changes,\"\\n\")\n",
    "\t\treturn None\n",
    "\telse:\n",
    "\t\tprint(combo,\"Changes to dataset:\",num_changes,\"\\n\")\n",
    "\t\treturn y_train_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_labels_trust(y_train,y_trust,y_trust_pred,train_cluster_labels,trust_cluster_labels,max_changes=np.inf):\n",
    "\ty_train_mod = np.copy(y_train)\n",
    "\tfor i in range(len(y_trust_pred)):\n",
    "\t\tif y_trust_pred[i]!=y_trust[i]:\n",
    "\t\t\tprint(\"Set Cluster\",trust_cluster_labels[i],\"to\",y_trust[i])\n",
    "\t\t\ty_train_mod[train_cluster_labels==trust_cluster_labels[i]] = y_trust[i]\n",
    "\tnum_changes = np.count_nonzero(y_train - y_train_mod)\n",
    "\tif num_changes>max_changes:\n",
    "\t\tprint(\"Too many changes to dataset:\",num_changes,\"\\n\")\n",
    "\t\treturn None\n",
    "\telse:\n",
    "\t\treturn y_train_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_labels_flip_one(y_train,train_cluster_labels,cluster_label,new_label,max_changes=np.inf):\n",
    "\ty_train_mod = np.copy(y_train)\n",
    "    \n",
    "\ty_train_mod[train_cluster_labels==cluster_label] = new_label\n",
    "    \n",
    "\tnum_changes = np.count_nonzero(y_train - y_train_mod)\n",
    "\tif num_changes>max_changes:\n",
    "\t\tprint(\"Too many changes to dataset:\",num_changes,\"\\n\")\n",
    "\t\treturn None\n",
    "\telse:\n",
    "\t\treturn y_train_mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_data(X_train, y_train, X_trust, y_trust, clf, \n",
    "                 min_K, max_K, max_changes=np.inf, combo_mode=\"trusted\", plot=False, cluster_with_labels=False):\n",
    "    \n",
    "    label_set = list(set(y_train))\n",
    "\n",
    "    # Visualize original dataset\n",
    "    print(\"Running Model without any modifications to dataset...\")\n",
    "\n",
    "    clf, y_pred, y_trust_pred, check = check_trusted_items(X_train,y_train,X_trust,y_trust,clf, plot=plot)\n",
    "    print(\"Number of bugs: %d\" % np.count_nonzero(y_train - y_pred))\n",
    "    evaluate_model(y_train,y_train, y_pred)\n",
    "\n",
    "    if check:\n",
    "        print(\"All trusted items classified correctly using original dataset! \\n\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    if combo_mode==\"all\":\n",
    "        print(\"Trying all labeling of clusters, from K = %d to %d\\n\"%(min_K,max_K))\n",
    "    elif combo_mode==\"trusted\":\n",
    "        print(\"Modifying only labels of clusters containing mislabeled trusted items, from K = %d to %d\\n\"%(min_K,max_K))\n",
    "    elif combo_mode==\"flip_one\":\n",
    "        print(\"Flipping labels of datapoints, one cluster at a time, from K = %d to %d\\n\"%(min_K,max_K))\n",
    "    \n",
    "        \n",
    "    if cluster_with_labels:\n",
    "        X_train_cluster = np.hstack((X_train, np.reshape(y_train,(y_train.shape[0],1))))\n",
    "        X_trust_cluster = np.hstack((X_trust, np.reshape(y_trust,(y_trust.shape[0],1))))\n",
    "    else:\n",
    "        X_train_cluster = np.copy(X_train)\n",
    "        X_trust_cluster = np.copy(X_trust)\n",
    "        \n",
    "    X_train_and_trust = np.vstack([X_train_cluster, X_trust_cluster])\n",
    "\n",
    "    categorical = [True for i in range(X_train_cluster.shape[1])]\n",
    "    categorical[1] = False\n",
    "    categorical[3] = False\n",
    "    \n",
    "    dist_matrix = gower_distances(X_train_and_trust, categorical_features=categorical)  \n",
    "    \n",
    "    for K in range(min_K,max_K+1):\n",
    "        \n",
    "        cluster_model = AgglomerativeClustering(n_clusters=K, affinity=\"precomputed\", linkage=\"complete\")\n",
    "#         cluster_model = AgglomerativeClustering(n_clusters=K, affinity=\"precomputed\", linkage=\"single\")\n",
    "        \n",
    "        \n",
    "        cluster_model.fit(dist_matrix)  \n",
    "        \n",
    "        \n",
    "        if K==min_K:\n",
    "            plot_dendrogram(cluster_model, labels=cluster_model.labels_)\n",
    "        \n",
    "        train_cluster_labels = cluster_model.labels_[:X_train.shape[0]]\n",
    "        trust_cluster_labels = cluster_model.labels_[X_train.shape[0]:]\n",
    "        train_counts = []\n",
    "        trust_counts = []\n",
    "        for i in range(K):\n",
    "            train_counts.append(np.sum(train_cluster_labels==i))\n",
    "            trust_counts.append(np.sum(trust_cluster_labels==i))\n",
    "        print(\"Clustering distribution:\",train_counts,trust_counts)  \n",
    "        \n",
    "\n",
    "        if combo_mode==\"all\":\n",
    "            print(\"Brute Force Clustering for K=%d\"%K)\n",
    "            all_combos = list(product(label_set, repeat=K)) \n",
    "            # this list contains every possible combination of labels for each cluster\n",
    "            \n",
    "            for combo in all_combos:\n",
    "                if len(set(combo))<=1:\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                y_train_mod = modify_labels(K, y_train, train_cluster_labels, combo, max_changes=max_changes)\n",
    "                if y_train_mod is None:\n",
    "                    continue\n",
    "\n",
    "                print(combo,\":\",)\n",
    "                clf, y_mod_pred, _, check = check_trusted_items(X_train,y_train_mod,X_trust,y_trust, clf, combo, \n",
    "                                                                train_cluster_labels, trust_cluster_labels)\n",
    "                \n",
    "                evaluate_model(y_train,y_train_mod, y_mod_pred)\n",
    "        \n",
    "        elif combo_mode==\"trusted\":\n",
    "            print(\"Trusted Clustering for K=%d\"%K)\n",
    "            y_train_mod = modify_labels_trust(y_train,y_trust,y_trust_pred,train_cluster_labels,trust_cluster_labels,max_changes=max_changes)\n",
    "            if y_train_mod is None:\n",
    "                continue\n",
    "\n",
    "            # print(y_trust_pred,y_trust)\n",
    "            # print \"List of points whose labels were changed:\",[i for i in range(len(y_train)) if y_train[i]!=y_train_mod[i]]\n",
    "            # print(train_cluster_labels,trust_cluster_labels)\n",
    "\n",
    "\n",
    "            clf, y_mod_pred, _, check = check_trusted_items(X_train,y_train_mod,X_trust,y_trust, clf, \n",
    "                                                        \"Trusted clustering: %d\"%K, train_cluster_labels, \n",
    "                                                        trust_cluster_labels, plot=plot)\n",
    "            \n",
    "            evaluate_model(y_train,y_train_mod,y_mod_pred)\n",
    "        \n",
    "        elif combo_mode==\"flip_one\":\n",
    "            print(\"Flip-One Clustering for K=%d\"%K)\n",
    "            \n",
    "            # For each cluster, try setting all possible labels for each cluster, one at a time, while keeping\n",
    "            # the labels of datapoints in other clusters to be the same\n",
    "            \n",
    "            for cluster_label in range(K):\n",
    "                for label in label_set:\n",
    "                    y_train_mod = modify_labels_flip_one(y_train,train_cluster_labels,cluster_label,label,\n",
    "                                                         max_changes=max_changes)\n",
    "                    print(\"Modified dataset by setting all labels in cluster %d to %d\"%(cluster_label,label))\n",
    "                    \n",
    "                    if y_train_mod is None:\n",
    "                        continue\n",
    "                        \n",
    "                    combo = \"K=%d, Cluster %d to %d\"%(K,cluster_label,label)\n",
    "\n",
    "                    clf, y_mod_pred, _, check = check_trusted_items(X_train,y_train_mod,X_trust,y_trust, clf, combo, \n",
    "                                                                    train_cluster_labels, trust_cluster_labels, plot=plot)\n",
    "\n",
    "                    evaluate_model(y_train,y_train_mod, y_mod_pred)\n",
    "            \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_changes = np.inf\n",
    "combo_mode = \"all\"\n",
    "combo_mode = \"trusted\"\n",
    "combo_mode = \"flip_one\"\n",
    "plot = False\n",
    "min_K = 5\n",
    "max_K = 8\n",
    "cluster_with_labels = False\n",
    "# cluster_with_labels = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model without any modifications to dataset...\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of bugs: 57\n",
      "Number of label changes made in dataset: 0\n",
      "Model Accuracy w.r.t. Original dataset:  83.23529411764706\n",
      "Model Accuracy w.r.t. Modified dataset:  83.23529411764706 \n",
      "\n",
      "\n",
      "Flipping labels of datapoints, one cluster at a time, from K = 5 to 8\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efbb5ea12e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering distribution: [82, 83, 135, 19, 21] [9, 7, 16, 6, 2]\n",
      "Flip-One Clustering for K=5\n",
      "Modified dataset by setting all labels in cluster 0 to 1\n",
      "6 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 31\n",
      "Model Accuracy w.r.t. Original dataset:  75.88235294117646\n",
      "Model Accuracy w.r.t. Modified dataset:  85.0 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 0 to -1\n",
      "13 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 51\n",
      "Model Accuracy w.r.t. Original dataset:  70.29411764705883\n",
      "Model Accuracy w.r.t. Modified dataset:  81.76470588235294 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 1 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 29\n",
      "Model Accuracy w.r.t. Original dataset:  76.47058823529412\n",
      "Model Accuracy w.r.t. Modified dataset:  84.41176470588235 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 1 to -1\n",
      "13 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 54\n",
      "Model Accuracy w.r.t. Original dataset:  68.23529411764706\n",
      "Model Accuracy w.r.t. Modified dataset:  81.17647058823529 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 2 to 1\n",
      "10 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 39\n",
      "Model Accuracy w.r.t. Original dataset:  77.05882352941177\n",
      "Model Accuracy w.r.t. Modified dataset:  87.94117647058823 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 2 to -1\n",
      "21 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 96\n",
      "Model Accuracy w.r.t. Original dataset:  57.64705882352941\n",
      "Model Accuracy w.r.t. Modified dataset:  79.41176470588235 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 3 to 1\n",
      "7 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 10\n",
      "Model Accuracy w.r.t. Original dataset:  82.05882352941177\n",
      "Model Accuracy w.r.t. Modified dataset:  83.82352941176471 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 3 to -1\n",
      "11 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 9\n",
      "Model Accuracy w.r.t. Original dataset:  80.58823529411765\n",
      "Model Accuracy w.r.t. Modified dataset:  80.88235294117646 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 4 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 6\n",
      "Model Accuracy w.r.t. Original dataset:  79.41176470588235\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 4 to -1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 15\n",
      "Model Accuracy w.r.t. Original dataset:  80.88235294117646\n",
      "Model Accuracy w.r.t. Modified dataset:  83.52941176470588 \n",
      "\n",
      "Clustering distribution: [83, 25, 135, 19, 21, 57] [7, 4, 16, 6, 2, 5]\n",
      "Flip-One Clustering for K=6\n",
      "Modified dataset by setting all labels in cluster 0 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 29\n",
      "Model Accuracy w.r.t. Original dataset:  76.47058823529412\n",
      "Model Accuracy w.r.t. Modified dataset:  84.41176470588235 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 0 to -1\n",
      "13 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 54\n",
      "Model Accuracy w.r.t. Original dataset:  68.23529411764706\n",
      "Model Accuracy w.r.t. Modified dataset:  81.17647058823529 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 1 to 1\n",
      "6 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 7\n",
      "Model Accuracy w.r.t. Original dataset:  81.76470588235294\n",
      "Model Accuracy w.r.t. Modified dataset:  83.23529411764706 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 1 to -1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 18\n",
      "Model Accuracy w.r.t. Original dataset:  78.82352941176471\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 2 to 1\n",
      "10 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 39\n",
      "Model Accuracy w.r.t. Original dataset:  77.05882352941177\n",
      "Model Accuracy w.r.t. Modified dataset:  87.94117647058823 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 2 to -1\n",
      "21 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 96\n",
      "Model Accuracy w.r.t. Original dataset:  57.64705882352941\n",
      "Model Accuracy w.r.t. Modified dataset:  79.41176470588235 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 3 to 1\n",
      "7 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 10\n",
      "Model Accuracy w.r.t. Original dataset:  82.05882352941177\n",
      "Model Accuracy w.r.t. Modified dataset:  83.82352941176471 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 3 to -1\n",
      "11 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 9\n",
      "Model Accuracy w.r.t. Original dataset:  80.58823529411765\n",
      "Model Accuracy w.r.t. Modified dataset:  80.88235294117646 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 4 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 6\n",
      "Model Accuracy w.r.t. Original dataset:  79.41176470588235\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 4 to -1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 15\n",
      "Model Accuracy w.r.t. Original dataset:  80.88235294117646\n",
      "Model Accuracy w.r.t. Modified dataset:  83.52941176470588 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 5 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 24\n",
      "Model Accuracy w.r.t. Original dataset:  77.6470588235294\n",
      "Model Accuracy w.r.t. Modified dataset:  83.52941176470588 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 5 to -1\n",
      "9 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 33\n",
      "Model Accuracy w.r.t. Original dataset:  74.70588235294117\n",
      "Model Accuracy w.r.t. Modified dataset:  81.47058823529412 \n",
      "\n",
      "Clustering distribution: [135, 25, 33, 19, 21, 57, 50] [16, 4, 4, 6, 2, 5, 3]\n",
      "Flip-One Clustering for K=7\n",
      "Modified dataset by setting all labels in cluster 0 to 1\n",
      "10 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 39\n",
      "Model Accuracy w.r.t. Original dataset:  77.05882352941177\n",
      "Model Accuracy w.r.t. Modified dataset:  87.94117647058823 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 0 to -1\n",
      "21 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 96\n",
      "Model Accuracy w.r.t. Original dataset:  57.64705882352941\n",
      "Model Accuracy w.r.t. Modified dataset:  79.41176470588235 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 1 to 1\n",
      "6 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 7\n",
      "Model Accuracy w.r.t. Original dataset:  81.76470588235294\n",
      "Model Accuracy w.r.t. Modified dataset:  83.23529411764706 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 1 to -1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 18\n",
      "Model Accuracy w.r.t. Original dataset:  78.82352941176471\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 2 to 1\n",
      "9 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 7\n",
      "Model Accuracy w.r.t. Original dataset:  81.47058823529412\n",
      "Model Accuracy w.r.t. Modified dataset:  82.94117647058823 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 2 to -1\n",
      "12 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 26\n",
      "Model Accuracy w.r.t. Original dataset:  74.11764705882354\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 3 to 1\n",
      "7 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 10\n",
      "Model Accuracy w.r.t. Original dataset:  82.05882352941177\n",
      "Model Accuracy w.r.t. Modified dataset:  83.82352941176471 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 3 to -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 9\n",
      "Model Accuracy w.r.t. Original dataset:  80.58823529411765\n",
      "Model Accuracy w.r.t. Modified dataset:  80.88235294117646 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 4 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 6\n",
      "Model Accuracy w.r.t. Original dataset:  79.41176470588235\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 4 to -1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 15\n",
      "Model Accuracy w.r.t. Original dataset:  80.88235294117646\n",
      "Model Accuracy w.r.t. Modified dataset:  83.52941176470588 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 5 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 24\n",
      "Model Accuracy w.r.t. Original dataset:  77.6470588235294\n",
      "Model Accuracy w.r.t. Modified dataset:  83.52941176470588 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 5 to -1\n",
      "9 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 33\n",
      "Model Accuracy w.r.t. Original dataset:  74.70588235294117\n",
      "Model Accuracy w.r.t. Modified dataset:  81.47058823529412 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 6 to 1\n",
      "9 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 22\n",
      "Model Accuracy w.r.t. Original dataset:  80.88235294117646\n",
      "Model Accuracy w.r.t. Modified dataset:  86.17647058823529 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 6 to -1\n",
      "11 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 28\n",
      "Model Accuracy w.r.t. Original dataset:  76.17647058823529\n",
      "Model Accuracy w.r.t. Modified dataset:  77.94117647058823 \n",
      "\n",
      "Clustering distribution: [125, 25, 33, 10, 21, 57, 50, 19] [15, 4, 4, 1, 2, 5, 3, 6]\n",
      "Flip-One Clustering for K=8\n",
      "Modified dataset by setting all labels in cluster 0 to 1\n",
      "10 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 36\n",
      "Model Accuracy w.r.t. Original dataset:  76.47058823529412\n",
      "Model Accuracy w.r.t. Modified dataset:  87.05882352941177 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 0 to -1\n",
      "17 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 89\n",
      "Model Accuracy w.r.t. Original dataset:  57.94117647058823\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 1 to 1\n",
      "6 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 7\n",
      "Model Accuracy w.r.t. Original dataset:  81.76470588235294\n",
      "Model Accuracy w.r.t. Modified dataset:  83.23529411764706 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 1 to -1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 18\n",
      "Model Accuracy w.r.t. Original dataset:  78.82352941176471\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 2 to 1\n",
      "9 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 7\n",
      "Model Accuracy w.r.t. Original dataset:  81.47058823529412\n",
      "Model Accuracy w.r.t. Modified dataset:  82.94117647058823 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 2 to -1\n",
      "12 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 26\n",
      "Model Accuracy w.r.t. Original dataset:  74.11764705882354\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 3 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 3\n",
      "Model Accuracy w.r.t. Original dataset:  81.76470588235294\n",
      "Model Accuracy w.r.t. Modified dataset:  82.6470588235294 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 3 to -1\n",
      "11 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 7\n",
      "Model Accuracy w.r.t. Original dataset:  80.58823529411765\n",
      "Model Accuracy w.r.t. Modified dataset:  80.29411764705883 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 4 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 6\n",
      "Model Accuracy w.r.t. Original dataset:  79.41176470588235\n",
      "Model Accuracy w.r.t. Modified dataset:  80.58823529411765 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 4 to -1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 15\n",
      "Model Accuracy w.r.t. Original dataset:  80.88235294117646\n",
      "Model Accuracy w.r.t. Modified dataset:  83.52941176470588 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 5 to 1\n",
      "8 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 24\n",
      "Model Accuracy w.r.t. Original dataset:  77.6470588235294\n",
      "Model Accuracy w.r.t. Modified dataset:  83.52941176470588 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 5 to -1\n",
      "9 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 33\n",
      "Model Accuracy w.r.t. Original dataset:  74.70588235294117\n",
      "Model Accuracy w.r.t. Modified dataset:  81.47058823529412 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 6 to 1\n",
      "9 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 22\n",
      "Model Accuracy w.r.t. Original dataset:  80.88235294117646\n",
      "Model Accuracy w.r.t. Modified dataset:  86.17647058823529 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 6 to -1\n",
      "11 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 28\n",
      "Model Accuracy w.r.t. Original dataset:  76.17647058823529\n",
      "Model Accuracy w.r.t. Modified dataset:  77.94117647058823 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 7 to 1\n",
      "7 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 10\n",
      "Model Accuracy w.r.t. Original dataset:  82.05882352941177\n",
      "Model Accuracy w.r.t. Modified dataset:  83.82352941176471 \n",
      "\n",
      "Modified dataset by setting all labels in cluster 7 to -1\n",
      "11 trusted items were incorrectly predicted. Continuing experiment...\n",
      "Number of label changes made in dataset: 9\n",
      "Model Accuracy w.r.t. Original dataset:  80.58823529411765\n",
      "Model Accuracy w.r.t. Modified dataset:  80.88235294117646 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Experimenting with clustering\n",
    "\n",
    "cluster_data(X_B, y_B, X_A, y_A, clf, min_K=min_K, max_K=max_K, \n",
    "             max_changes=max_changes,combo_mode=combo_mode, plot=plot, \n",
    "             cluster_with_labels=cluster_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
